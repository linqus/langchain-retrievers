{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.3.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from sentence-transformers) (4.37.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
      "Requirement already satisfied: click in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\karol\\anaconda3\\envs\\langchain\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
      "   ---------------------------------------- 0.0/132.8 kB ? eta -:--:--\n",
      "   --------- ----------------------------- 30.7/132.8 kB 660.6 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 122.9/132.8 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 132.8/132.8 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.4.1.post1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/10.6 MB 12.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.0/10.6 MB 10.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 2.4/10.6 MB 16.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.2/10.6 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.1/10.6 MB 25.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.3/10.6 MB 29.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.3/10.6 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 34.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 31.2 MB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 991.5/991.5 kB 31.7 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: sentencepiece, threadpoolctl, scikit-learn, sentence-transformers\n",
      "Successfully installed scikit-learn-1.4.1.post1 sentence-transformers-2.3.1 sentencepiece-0.2.0 threadpoolctl-3.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='This is a document about the Boston Celtics'),\n",
       " Document(page_content='The Celtics are my favourite team.'),\n",
       " Document(page_content='L. Kornet is one of the best Celtics players.'),\n",
       " Document(page_content='The Boston Celtics won the game by 20 points'),\n",
       " Document(page_content='Larry Bird was an iconic NBA player.'),\n",
       " Document(page_content='Elden Ring is one of the best games in the last 15 years.'),\n",
       " Document(page_content='Basquetball is a great sport.'),\n",
       " Document(page_content='I simply love going to the movies'),\n",
       " Document(page_content='Fly me to the moon is one of my favourite songs.'),\n",
       " Document(page_content='This is just a random text.')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain, StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Get embeddings.\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "texts = [\n",
    "    \"Basquetball is a great sport.\",\n",
    "    \"Fly me to the moon is one of my favourite songs.\",\n",
    "    \"The Celtics are my favourite team.\",\n",
    "    \"This is a document about the Boston Celtics\",\n",
    "    \"I simply love going to the movies\",\n",
    "    \"The Boston Celtics won the game by 20 points\",\n",
    "    \"This is just a random text.\",\n",
    "    \"Elden Ring is one of the best games in the last 15 years.\",\n",
    "    \"L. Kornet is one of the best Celtics players.\",\n",
    "    \"Larry Bird was an iconic NBA player.\",\n",
    "]\n",
    "\n",
    "# Create a retriever\n",
    "retriever = Chroma.from_texts(texts, embedding=embeddings).as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")\n",
    "query = \"What can you tell me about the Celtics?\"\n",
    "\n",
    "# Get relevant documents ordered by relevance score\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='The Celtics are my favourite team.'),\n",
       " Document(page_content='The Boston Celtics won the game by 20 points'),\n",
       " Document(page_content='Elden Ring is one of the best games in the last 15 years.'),\n",
       " Document(page_content='I simply love going to the movies'),\n",
       " Document(page_content='This is just a random text.'),\n",
       " Document(page_content='Fly me to the moon is one of my favourite songs.'),\n",
       " Document(page_content='Basquetball is a great sport.'),\n",
       " Document(page_content='Larry Bird was an iconic NBA player.'),\n",
       " Document(page_content='L. Kornet is one of the best Celtics players.'),\n",
       " Document(page_content='This is a document about the Boston Celtics')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder the documents:\n",
    "# Less relevant document will be at the middle of the list and more\n",
    "# relevant elements at beginning / end.\n",
    "reordering = LongContextReorder()\n",
    "reordered_docs = reordering.transform_documents(docs)\n",
    "\n",
    "# Confirm that the 4 relevant documents are at beginning and end.\n",
    "reordered_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\karol\\anaconda3\\envs\\langchain\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nSome potential answers based on the given text extracts could be:\\n\\n- The Celtics are someone's favorite team.\\n- The Boston Celtics won a game by 20 points.\\n- L. Kornet is one of the best Celtics players.\\n- This is a document about the Boston Celtics.\\n- Larry Bird was an iconic NBA player.\\n- The Boston Celtics are a basketball team.\\n- The Boston Celtics are mentioned in multiple texts.\\n- The Celtics have a player named L. Kornet.\\n- The Celtics have a connection to the city of Boston.\\n- The Celtics won a game by 20 points in the past.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We prepare and run a custom Stuff chain with reordered docs as context.\n",
    "\n",
    "# Override prompts\n",
    "document_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\"], template=\"{page_content}\"\n",
    ")\n",
    "document_variable_name = \"context\"\n",
    "llm = OpenAI()\n",
    "stuff_prompt_override = \"\"\"Given this text extracts:\n",
    "-----\n",
    "{context}\n",
    "-----\n",
    "Please answer the following question:\n",
    "{query}\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=stuff_prompt_override, input_variables=[\"context\", \"query\"]\n",
    ")\n",
    "\n",
    "# Instantiate the chain\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=document_variable_name,\n",
    ")\n",
    "chain.run(input_documents=reordered_docs, query=query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
